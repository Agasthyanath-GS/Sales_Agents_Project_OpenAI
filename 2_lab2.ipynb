{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, function_tool\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from typing import Dict\n",
    "import os\n",
    "import asyncio\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "MAIL_KEY = os.getenv(\"MAIL_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_email( Subject:str, content:str )->Dict[str,str]:\n",
    "    sender_email = \"agasthybot@gmail.com\"\n",
    "    receiver_email = \"agasthynathgs@gmail.com\"\n",
    "    app_password   = MAIL_KEY # Replace this\n",
    "\n",
    "    # Create message\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "    message[\"Subject\"] = Subject\n",
    "    body = content\n",
    "    message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    # Connect to Gmail SMTP\n",
    "    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "    server.starttls()\n",
    "    server.login(sender_email, app_password)\n",
    "    server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "    server.quit()\n",
    "\n",
    "    return {\"status\" : \"success\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "response = send_email(\"test\",\"testing mail 2\")\n",
    "print(response[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Agent workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions1 = \"You are a sales agent working for BrokeAI, \\\n",
    "a company that provides a Agentic AI solution for customer support and customer complience. \\\n",
    "You write professional, serious cold emails.\"\n",
    "\n",
    "instructions2 = \"You are a humorous, engaging sales agent working for BrokeAI, \\\n",
    "a company that provides a Agentic AI solution for customer support and customer complience. \\\n",
    "You write witty, engaging cold emails that are likely to get a response.\"\n",
    "\n",
    "instructions3 = \"You are a busy sales agent working for BrokeAI, \\\n",
    "a company that provides a Agentic AI solution for customer support and customer complience. \\\n",
    "You write concise, to the point cold emails.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent1 = Agent(name = \"proffetional agent\",instructions=instructions1,model=\"gpt-4o-mini\")\n",
    "Agent2 = Agent(name=\"engaging agent\",instructions=instructions2,model=\"gpt-4o-mini\")\n",
    "Agent3 = Agent(name=\"busy agent\",instructions=instructions3,model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Transform Your Customer Support with Agentic AI Solutions\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well.\n",
      "\n",
      "My name is [Your Name], and I represent BrokeAI, where we specialize in advanced AI solutions designed to enhance customer support and compliance processes. \n",
      "\n",
      "In today’s fast-paced business environment, delivering exceptional customer service is more crucial than ever. Our Agentic AI technology not only streamlines customer interactions but also ensures compliance with industry standards, allowing your team to focus on what they do best.\n",
      "\n",
      "Here are a few ways our solution can benefit your organization:\n",
      "\n",
      "- **24/7 Customer Support:** Provide instant responses to queries, reducing wait times and improving customer satisfaction.\n",
      "- **Automated Compliance Checks:** Ensure adherence to regulations automatically, minimizing risks and potential liabilities.\n",
      "- **Scalable Solutions:** Easily adapt to business growth without the need for extensive human resources.\n",
      "\n",
      "I would love the opportunity to discuss how our AI solutions can specifically address your needs. Are you available for a brief call next week?\n",
      "\n",
      "Thank you for considering BrokeAI. I look forward to the possibility of working together.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "BrokeAI  \n",
      "[Your Phone Number]  \n",
      "[Your LinkedIn Profile]  \n",
      "[Website URL]  "
     ]
    }
   ],
   "source": [
    "#testing the runner\n",
    "result =  Runner.run_streamed(Agent1, \"Write a cold sales email\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting an agent as sales manager who deside the best mail\n",
    "sales_manager = Agent(name=\"sales_manager\",model=\"gpt-4o-mini\", instructions= \"You pick the best cold sales email from the given options. \\\n",
    "                                                                                    Imagine you are a sales manager and pick the one you are most likely to send to customer's. \\\n",
    "                                                                                    Do not give an explanation; reply with the selected email only.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sales email:\n",
      "Subject: Enhance Your Customer Support with Agentic AI\n",
      "\n",
      "Dear [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. My name is [Your Name], and I represent BrokeAI, where we specialize in streamlining customer support with our cutting-edge Agentic AI solution.\n",
      "\n",
      "In today’s fast-paced environment, businesses face the challenge of meeting rising customer expectations while maintaining operational efficiency. Our Agentic AI not only enhances response times but also ensures compliance with industry regulations, allowing your team to focus on what truly matters — building lasting relationships with your customers.\n",
      "\n",
      "By integrating our solution, you can expect:\n",
      "\n",
      "- **24/7 Availability**: Provide immediate assistance, even outside business hours.\n",
      "- **Personalized Interactions**: Utilize data analytics to engage with customers on a more personal level.\n",
      "- **Compliance Assurance**: Stay ahead of regulatory requirements effortlessly.\n",
      "\n",
      "I would love the opportunity to discuss how BrokeAI can help your team optimize customer support operations. Are you available for a brief call next week?\n",
      "\n",
      "Thank you for considering this; I look forward to the possibility of working together.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Title]  \n",
      "BrokeAI  \n",
      "[Your Phone Number]  \n",
      "[Your Email Address]  \n",
      "[Website URL]  \n"
     ]
    }
   ],
   "source": [
    "# executing the sales manager agent to find the best mail\n",
    "message = \"Write a cold sales email\"\n",
    "with trace(\"test\"):\n",
    "    results = await asyncio.gather(\n",
    "        Runner.run(Agent1, message),\n",
    "        Runner.run(Agent2, message),\n",
    "        Runner.run(Agent3, message))\n",
    "    predictions = [result.final_output for result in results]\n",
    "    emails      = \"Cold sales emails:\\n\\n\" + \"\\n\\nEmail:\\n\\n\".join(predictions)\n",
    "    best_email  = await Runner.run(sales_manager, emails)\n",
    "\n",
    "    print(f\"Best sales email:\\n{best_email.final_output}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 2 and 3: Tools and Agent interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So now we can gather all the tools together:\n",
    "\n",
    "A tool for each of our 3 email-writing agents\n",
    "\n",
    "And a tool for our function to send emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='sales_Agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_Agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x115fe89a0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='sales_Agent2', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_Agent2_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x115fe9ee0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='sales_Agent3', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_Agent3_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x115fea2a0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='send_email', description='', params_json_schema={'properties': {'Subject': {'title': 'Subject', 'type': 'string'}, 'content': {'title': 'Content', 'type': 'string'}}, 'required': ['Subject', 'content'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1145cf880>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up agents as tools\n",
    "description = \"Write a cold sales email\"\n",
    "tool1 = Agent1.as_tool(tool_name=\"sales_Agent1\",tool_description=description)\n",
    "tool2 = Agent2.as_tool(tool_name=\"sales_Agent2\",tool_description=description)\n",
    "tool3 = Agent3.as_tool(tool_name=\"sales_Agent3\",tool_description=description)\n",
    "\n",
    "tools = [tool1,tool2,tool3,send_email]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now it's time for our Sales Manager - our planning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved instructions thanks to student Guillermo F.\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are a Sales Manager at ComplAI. Your goal is to find the single best cold sales email using the sales Agents tools.\n",
    " \n",
    "Follow these steps carefully:\n",
    "\n",
    "1. Generate Drafts: Use all three sales Agents tools to generate three different email drafts. Do not proceed until all three drafts are ready.\n",
    " \n",
    "2. Evaluate and Select: Review the drafts and choose the single best email using your judgment of which one is most effective for customer.\n",
    " \n",
    "3. Use the send_email tool to send the best email (and only the best email) to the user.\n",
    " \n",
    "Crucial Rules:\n",
    "- You must use the Agents tools to generate the drafts — do not write them yourself.\n",
    "- You must send ONE email using the send_email tool — never more than one.\n",
    "- Do not pass any instruction to sales Agents, they are already given their instructions.\n",
    "- You must strictly follow the rules.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(name=\"Sales Manager\", instructions=instructions, tools=tools, model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send a cold sales email addressed to 'Dear CEO'\"\n",
    "\n",
    "with trace(\"Sales manager\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "And then check your email!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handoffs represent a way an agent can delegate to an agent, passing control to it\n",
    "\n",
    "Handoffs and Agents-as-tools are similar:\n",
    "\n",
    "In both cases, an Agent can collaborate with another Agent\n",
    "\n",
    "With tools, control passes back\n",
    "\n",
    "With handoffs, control passes across\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_instructions = \"You can write a subject for a cold sales email. \\\n",
    "You are given a message and you need to write a subject for an email that is likely to get a response.\"\n",
    "\n",
    "html_instructions = \"You can convert a text email body to an HTML email body. \\\n",
    "You are given a text email body which might have some markdown \\\n",
    "and you need to convert it to an HTML email body with simple, clear, compelling layout and design.\"\n",
    "\n",
    "subject_writer = Agent(name=\"Email subject writer\", instructions=subject_instructions, model=\"gpt-4o-mini\")\n",
    "subject_tool = subject_writer.as_tool(tool_name=\"subject_writer\", tool_description=\"Write a subject for a cold sales email\")\n",
    "\n",
    "html_converter = Agent(name=\"HTML email body converter\", instructions=html_instructions, model=\"gpt-4o-mini\")\n",
    "html_tool = html_converter.as_tool(tool_name=\"html_converter\",tool_description=\"Convert a text email body to an HTML email body\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_html_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\" Send out an email with the given subject and HTML body to all sales prospects \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"ed@edwarddonner.com\")  # Change to your verified sender\n",
    "    to_email = To(\"ed.donner@gmail.com\")  # Change to your recipient\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [subject_tool, html_tool, send_html_email]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionTool(name='subject_writer', description='Write a subject for a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'subject_writer_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x113209e40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='html_converter', description='Convert a text email body to an HTML email body', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'html_converter_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x113209800>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None),\n",
       " FunctionTool(name='send_html_email', description='Send out an email with the given subject and HTML body to all sales prospects', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_html_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1145cc5e0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions =\"You are an email formatter and sender. You receive the body of an email to be sent. \\\n",
    "You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. \\\n",
    "Finally, you use the send_html_email tool to send the email with the subject and HTML body.\"\n",
    "\n",
    "\n",
    "emailer_agent = Agent(\n",
    "    name=\"Email Manager\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoff_description=\"Convert an email to HTML and send it\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have 3 tools and 1 handoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionTool(name='sales_agent1', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent1_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1145f1300>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='sales_agent2', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent2_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1145f1ee0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='sales_agent3', description='Write a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'sales_agent3_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1145f2340>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)]\n",
      "[Agent(name='Email Manager', handoff_description='Convert an email to HTML and send it', tools=[FunctionTool(name='subject_writer', description='Write a subject for a cold sales email', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'subject_writer_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x113209e40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='html_converter', description='Convert a text email body to an HTML email body', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'html_converter_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x113209800>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='send_html_email', description='Send out an email with the given subject and HTML body to all sales prospects', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_html_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x1145cc5e0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions='You are an email formatter and sender. You receive the body of an email to be sent. You first use the subject_writer tool to write a subject for the email, then use the html_converter tool to convert the body to HTML. Finally, you use the send_html_email tool to send the email with the subject and HTML body.', prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)]\n"
     ]
    }
   ],
   "source": [
    "tools = [tool1, tool2, tool3]\n",
    "handoffs = [emailer_agent]\n",
    "print(tools)\n",
    "print(handoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agasthy/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/ast.py:280: RuntimeWarning: coroutine 'Runner.run' was never awaited\n",
      "  yield item\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33mSend out a cold sales email addressed to Dear CEO from Alice\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace(\u001b[33m\"\u001b[39m\u001b[33mAutomated SDR\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(sales_manager, message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/agents/run.py:296\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, conversation_id, session)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mRun a workflow starting at the given agent.\u001b[39;00m\n\u001b[32m    249\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    292\u001b[39m \u001b[33;03m    type of the output.\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    295\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    297\u001b[39m     starting_agent,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    299\u001b[39m     context=context,\n\u001b[32m    300\u001b[39m     max_turns=max_turns,\n\u001b[32m    301\u001b[39m     hooks=hooks,\n\u001b[32m    302\u001b[39m     run_config=run_config,\n\u001b[32m    303\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    304\u001b[39m     conversation_id=conversation_id,\n\u001b[32m    305\u001b[39m     session=session,\n\u001b[32m    306\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/agents/run.py:571\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    549\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_input_guardrails(\n\u001b[32m    550\u001b[39m             starting_agent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    568\u001b[39m         ),\n\u001b[32m    569\u001b[39m     )\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    572\u001b[39m         agent=current_agent,\n\u001b[32m    573\u001b[39m         all_tools=all_tools,\n\u001b[32m    574\u001b[39m         original_input=original_input,\n\u001b[32m    575\u001b[39m         generated_items=generated_items,\n\u001b[32m    576\u001b[39m         hooks=hooks,\n\u001b[32m    577\u001b[39m         context_wrapper=context_wrapper,\n\u001b[32m    578\u001b[39m         run_config=run_config,\n\u001b[32m    579\u001b[39m         should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    580\u001b[39m         tool_use_tracker=tool_use_tracker,\n\u001b[32m    581\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    582\u001b[39m         conversation_id=conversation_id,\n\u001b[32m    583\u001b[39m     )\n\u001b[32m    584\u001b[39m should_run_agent_start_hooks = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    586\u001b[39m model_responses.append(turn_result.model_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/agents/run.py:1246\u001b[39m, in \u001b[36mAgentRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id, conversation_id)\u001b[39m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m   1244\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m   1247\u001b[39m     agent,\n\u001b[32m   1248\u001b[39m     system_prompt,\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1250\u001b[39m     output_schema,\n\u001b[32m   1251\u001b[39m     all_tools,\n\u001b[32m   1252\u001b[39m     handoffs,\n\u001b[32m   1253\u001b[39m     hooks,\n\u001b[32m   1254\u001b[39m     context_wrapper,\n\u001b[32m   1255\u001b[39m     run_config,\n\u001b[32m   1256\u001b[39m     tool_use_tracker,\n\u001b[32m   1257\u001b[39m     previous_response_id,\n\u001b[32m   1258\u001b[39m     conversation_id,\n\u001b[32m   1259\u001b[39m     prompt_config,\n\u001b[32m   1260\u001b[39m )\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m   1263\u001b[39m     agent=agent,\n\u001b[32m   1264\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1273\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m   1274\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/agents/run.py:1494\u001b[39m, in \u001b[36mAgentRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, hooks, context_wrapper, run_config, tool_use_tracker, previous_response_id, conversation_id, prompt_config)\u001b[39m\n\u001b[32m   1479\u001b[39m \u001b[38;5;66;03m# If we have run hooks, or if the agent has hooks, we need to call them before the LLM call\u001b[39;00m\n\u001b[32m   1480\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m   1481\u001b[39m     hooks.on_llm_start(context_wrapper, agent, filtered.instructions, filtered.input),\n\u001b[32m   1482\u001b[39m     (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1491\u001b[39m     ),\n\u001b[32m   1492\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m   1495\u001b[39m     system_instructions=filtered.instructions,\n\u001b[32m   1496\u001b[39m     \u001b[38;5;28minput\u001b[39m=filtered.input,\n\u001b[32m   1497\u001b[39m     model_settings=model_settings,\n\u001b[32m   1498\u001b[39m     tools=all_tools,\n\u001b[32m   1499\u001b[39m     output_schema=output_schema,\n\u001b[32m   1500\u001b[39m     handoffs=handoffs,\n\u001b[32m   1501\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m   1502\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m   1503\u001b[39m     ),\n\u001b[32m   1504\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m   1505\u001b[39m     conversation_id=conversation_id,\n\u001b[32m   1506\u001b[39m     prompt=prompt_config,\n\u001b[32m   1507\u001b[39m )\n\u001b[32m   1509\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m   1511\u001b[39m \u001b[38;5;66;03m# If we have run hooks, or if the agent has hooks, we need to call them after the LLM call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:90\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, conversation_id, prompt)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     91\u001b[39m             system_instructions,\n\u001b[32m     92\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     93\u001b[39m             model_settings,\n\u001b[32m     94\u001b[39m             tools,\n\u001b[32m     95\u001b[39m             output_schema,\n\u001b[32m     96\u001b[39m             handoffs,\n\u001b[32m     97\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m     98\u001b[39m             conversation_id=conversation_id,\n\u001b[32m     99\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    100\u001b[39m             prompt=prompt,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m    104\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:305\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, conversation_id, stream, prompt)\u001b[39m\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    303\u001b[39m         response_format = {\u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: model_settings.verbosity}\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    306\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    307\u001b[39m     conversation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(conversation_id),\n\u001b[32m    308\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    309\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    310\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    311\u001b[39m     include=include,\n\u001b[32m    312\u001b[39m     tools=converted_tools_payload,\n\u001b[32m    313\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(prompt),\n\u001b[32m    314\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    315\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    316\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    317\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    318\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    319\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    320\u001b[39m     stream=stream,\n\u001b[32m    321\u001b[39m     extra_headers=\u001b[38;5;28mself\u001b[39m._merge_headers(model_settings),\n\u001b[32m    322\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    323\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    324\u001b[39m     text=response_format,\n\u001b[32m    325\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    326\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    327\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    328\u001b[39m     **extra_args,\n\u001b[32m    329\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:2259\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2222\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   2223\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2224\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2257\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   2258\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m2259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2260\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2261\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2262\u001b[39m             {\n\u001b[32m   2263\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   2264\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mconversation\u001b[39m\u001b[33m\"\u001b[39m: conversation,\n\u001b[32m   2265\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   2266\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2267\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   2268\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   2269\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: max_tool_calls,\n\u001b[32m   2270\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2271\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2272\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2273\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   2274\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m   2275\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2276\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   2277\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2278\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2279\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2280\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2281\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2282\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2283\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   2284\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2285\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2286\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2287\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2288\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   2289\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2290\u001b[39m             },\n\u001b[32m   2291\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   2292\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2293\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   2294\u001b[39m         ),\n\u001b[32m   2295\u001b[39m         options=make_request_options(\n\u001b[32m   2296\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2297\u001b[39m         ),\n\u001b[32m   2298\u001b[39m         cast_to=Response,\n\u001b[32m   2299\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2300\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   2301\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1794\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1780\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1781\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1782\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1789\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1790\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1791\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1792\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1793\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1529\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1527\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1528\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1530\u001b[39m         request,\n\u001b[32m   1531\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1532\u001b[39m         **kwargs,\n\u001b[32m   1533\u001b[39m     )\n\u001b[32m   1534\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1535\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/anyio/streams/tls.py:237\u001b[39m, in \u001b[36mTLSStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m = \u001b[32m65536\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_sslobject_method(\u001b[38;5;28mself\u001b[39m._ssl_object.read, max_bytes)\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/anyio/streams/tls.py:180\u001b[39m, in \u001b[36mTLSStream._call_sslobject_method\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._write_bio.pending:\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.send(\u001b[38;5;28mself\u001b[39m._write_bio.read())\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.receive()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m._read_bio.write_eof()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Gen-AI/agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:1263\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1258\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1261\u001b[39m ):\n\u001b[32m   1262\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1264\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/asyncio/locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Improved instructions thanks to student Guillermo F.\n",
    "\n",
    "sales_manager_instructions = \"\"\"\n",
    "You are a Sales Manager at BrokeAI. Your goal is to find the single best cold sales email using the sales_agent tools.\n",
    " \n",
    "Follow these steps carefully:\n",
    "1. Generate Drafts: Use all three sales_agent tools to generate three different email drafts. Do not proceed until all three drafts are ready.\n",
    " \n",
    "2. Evaluate and Select: Review the drafts and choose the single best email using your judgment of which one is most effective.\n",
    "You can use the tools multiple times if you're not satisfied with the results from the first try.\n",
    " \n",
    "3. Handoff for Sending: Pass ONLY the winning email draft to the 'Email Manager' agent. The Email Manager will take care of formatting and sending.\n",
    " \n",
    "Crucial Rules:\n",
    "- You must use the sales agent tools to generate the drafts — do not write them yourself.\n",
    "- You must hand off exactly ONE email to the Email Manager — never more than one.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sales_manager = Agent(\n",
    "    name=\"Sales Manager\",\n",
    "    instructions=sales_manager_instructions,\n",
    "    tools=tools,\n",
    "    handoffs=handoffs,\n",
    "    model=\"gpt-4o-mini\")\n",
    "\n",
    "message = \"Send out a cold sales email addressed to Dear CEO from Alice\"\n",
    "\n",
    "with trace(\"Automated SDR\"):\n",
    "    result = await Runner.run(sales_manager, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to check the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "And then check your email!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra note:\n",
    "\n",
    "Google has released their Agent Development Kit (ADK). It's not yet got the traction of the other frameworks on this course, but it's getting some attention. It's interesting to note that it looks quite similar to OpenAI Agents SDK. To give you a preview, here's a peak at sample code from ADK:\n",
    "\n",
    "```\n",
    "root_agent = Agent(\n",
    "    name=\"weather_time_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Agent to answer questions about the time and weather in a city.\",\n",
    "    instruction=\"You are a helpful agent who can answer user questions about the time and weather in a city.\",\n",
    "    tools=[get_weather, get_current_time]\n",
    ")\n",
    "```\n",
    "\n",
    "Well, that looks familiar!\n",
    "\n",
    "And a student has contributed a customer care agent in community_contributions that uses ADK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
